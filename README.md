# Chained deep learning using generalized cross entropy for multiple annotators segmentation

Given a $k$ class multiple annotators segmentation problem with a dataset like the following:

$$
X âˆˆ â„^{W Ã— H}, { Y_r âˆˆ {0,1}^{W Ã— H Ã— K} }_{r=1}^R; YÌ‚ âˆˆ [0,1]^{WÃ—HÃ—K} = f(X)
$$

The segmentation mask function will map input output as follows:

$$
f: \mathbb{R}^{W\times H} \to [0,1]^{W\times H\times K}
$$

$\mathbf Y$ will satisfy the following condition for being a softmax-like representation:

$$
Y_r[w,h,:] 1^âŠ¤_k = 1; w âˆˆ W, h âˆˆ H
$$

Now, let's suppose the existence of an annotators reliability map estimation $ğ›Œ_r; r âˆˆ R$:

$$
Y_r[w,h,:] 1^âŠ¤_k = 1; w âˆˆ W, h âˆˆ H
$$

Then, our $TGCE_{SS}$ is defined as:

$$
TGCE_SS(Y_r, f(X; Î¸) | ğ›Œ_r(X; Î¸)) = E_r { E_{w,h} { ğ›Œ_r(X; Î¸) â—¦ E_k { Y_r â—¦ ((1_{WÃ—HÃ—K} - f(X; Î¸)^{âˆ˜ q }) / q); k âˆˆ K } + (1_{WÃ—H} - ğ›Œ_r(X; Î¸)) â—¦ ((1_{WÃ—H} - ((1/k) 1_{WÃ—H})^{âˆ˜ q}) / q); w âˆˆ W, h âˆˆ H }; r âˆˆ R }
$$

Where $q \in (0,1)$.

The total loss for a given batch holding $N$ samples is:

$$
\mathscr{L}\left(\mathbf{Y}_r[n],f(\mathbf X[n];\theta) | \mathbf{\Lambda}_r (\mathbf X[n];\theta)\right)  = \frac{1}{N} \sum_{n}^NTGCE_{SS}(\mathbf{Y}_r[n],f(\mathbf X[n];\theta) | \mathbf{\Lambda}_r (\mathbf X[n];\theta))
$$
